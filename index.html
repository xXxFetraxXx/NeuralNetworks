<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="description" content="Multi-Layer Perceptrons with Fourier encoding, visualization and PyTorch compilation" /><meta name="author" content="Alexandre Brun" /><link rel="canonical" href="https://xXxFetraxXx.github.io/NeuralNetworks/" />
      <link rel="shortcut icon" href="img/favicon.ico" />
    <title>NeuralNetworks</title>
    <link rel="stylesheet" href="css/theme.css" />
    <link rel="stylesheet" href="css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Accueil";
        var mkdocs_page_input_path = "index.md";
        var mkdocs_page_url = "/NeuralNetworks/";
      </script>
    
    <!--[if lt IE 9]>
      <script src="js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="." class="icon icon-home"> NeuralNetworks
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">Accueil</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#contenu-principal">Contenu principal</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#classes">Classes</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#mlp">MLP</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#fonctions-utilitaires">Fonctions utilitaires</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#visualisation-et-comparaison">Visualisation et comparaison</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#objets-et-dictionnaires">Objets et dictionnaires</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#norms">norms()</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#crits">crits()</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#optims">optims()</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#device-et-configuration">Device et configuration</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#apple-silicon-macos">Apple Silicon (macOS)</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#windows">Windows</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#linux">Linux</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#systeme-non-reconnu">Système non reconnu</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#parametres-matplotlib-et-pytorch">Paramètres matplotlib et PyTorch</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#notes-generales">Notes générales</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">MLP</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="MLP/">MLP</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="MLP/params/">MLP.params</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="MLP/neurons/">MLP.neurons</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="MLP/nb_params/">MLP.nb_params</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="MLP/plot/">MLP.plot</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="MLP/train/">MLP.train</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Plots</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="Plots/plot/">plot</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="Plots/compare/">compare</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="Plots/losses/">losses</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="Plots/train/">train</a>
                  </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="Image/image_from_url/">image_from_url</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="" href="https://pypi.org/project/NeuralNetworks/">PyPI</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href=".">NeuralNetworks</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Accueil</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/xXxFetraxXx/NeuralNetworks/edit/master/docs/index.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="neuralnetworks-module">NeuralNetworks Module<a class="headerlink" href="#neuralnetworks-module" title="Permanent link">&para;</a></h1>
<p>Module complet pour la création, l'entraînement et la visualisation de Multi-Layer Perceptrons (MLP)<br />
avec encodage optionnel Fourier, gestion automatique des pertes, compilation Torch et outils<br />
de traitement d'images pour l'apprentissage sur des images RGB.</p>
<hr />
<h2 id="contenu-principal">Contenu principal<a class="headerlink" href="#contenu-principal" title="Permanent link">&para;</a></h2>
<h3 id="classes">Classes<a class="headerlink" href="#classes" title="Permanent link">&para;</a></h3>
<h4 id="mlp">MLP<a class="headerlink" href="#mlp" title="Permanent link">&para;</a></h4>
<p>Multi-Layer Perceptron (MLP) avec options avancées :</p>
<ul>
<li>Encodage Fourier gaussien (RFF) optionnel  </li>
<li>Stockage automatique des pertes  </li>
<li>Compilation Torch optionnelle pour accélérer l’inférence  </li>
<li>Gestion flexible de l’optimiseur, de la fonction de perte et de la normalisation  </li>
</ul>
<p><strong>Méthodes principales :</strong></p>
<ul>
<li>
<p><code>__init__(layers, learning_rate, Fourier, optimizer, criterion, normalizer, name, Iscompiled)</code><br />
  Initialise le réseau avec toutes les options.</p>
</li>
<li>
<p><code>train(inputs, outputs, num_epochs, batch_size)</code><br />
  Entraîne le MLP sur des données (<code>inputs → outputs</code>) en utilisant AMP et mini-batchs.</p>
</li>
<li>
<p><code>plot(inputs, img_array)</code><br />
  Affiche l'image originale, la prédiction du MLP et la courbe des pertes.</p>
</li>
<li>
<p><code>__call__(x)</code><br />
  Applique l’encodage puis le MLP pour produire une prédiction.</p>
</li>
<li>
<p><code>Create_MLP(layers)</code><br />
  Construit le MLP avec normalisation/activation et Sigmoid finale.</p>
</li>
<li>
<p><code>params()</code><br />
  Retourne tous les poids du MLP (ligne par ligne) sous forme de liste de <code>numpy.ndarray</code>.</p>
</li>
<li>
<p><code>nb_params()</code><br />
  Calcule le nombre total de poids dans le MLP.</p>
</li>
<li>
<p><code>neurons()</code><br />
  Retourne la liste des biais (neurones) de toutes les couches linéaires.</p>
</li>
<li>
<p><code>__repr__()</code><br />
  Affiche un schéma visuel du MLP via visualtorch et print des dimensions.</p>
</li>
</ul>
<hr />
<h3 id="fonctions-utilitaires">Fonctions utilitaires<a class="headerlink" href="#fonctions-utilitaires" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><code>tensorise(obj)</code><br />
  Convertit un objet array-like ou tensor en <code>torch.Tensor</code> float32 sur le device actif.</p>
</li>
<li>
<p><code>rglen(list)</code><br />
  Renvoie un range correspondant aux indices d'une liste.</p>
</li>
<li>
<p><code>fPrintDoc(obj)</code><br />
  Crée une fonction lambda qui affiche le docstring d'un objet.</p>
</li>
<li>
<p><code>image_from_url(url, img_size)</code><br />
  Télécharge une image depuis une URL, la redimensionne et génère :</p>
</li>
<li><code>img_array</code> : <code>np.ndarray (H, W, 3)</code> pour affichage.  </li>
<li><code>inputs</code> : tenseur <code>(H*W, 2)</code> coordonnées normalisées.  </li>
<li><code>outputs</code> : tenseur <code>(H*W, 3)</code> valeurs RGB cibles.</li>
</ul>
<hr />
<h3 id="visualisation-et-comparaison">Visualisation et comparaison<a class="headerlink" href="#visualisation-et-comparaison" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><code>plot(img_array, inputs, *nets)</code><br />
  Affiche pour chaque réseau l'image reconstruite à partir des entrées.</p>
</li>
<li>
<p><code>compare(img_array, inputs, *nets)</code><br />
  Affiche pour chaque réseau l'erreur absolue entre l'image originale et la prédiction,<br />
  et trace également les pertes cumulées. Chaque réseau doit posséder :  </p>
</li>
<li><code>encoding(x)</code> si RFF activé  </li>
<li><code>model()</code> retournant un tenseur <code>(N, 3)</code>  </li>
<li>attribut <code>losses</code></li>
</ul>
<hr />
<h3 id="objets-et-dictionnaires">Objets et dictionnaires<a class="headerlink" href="#objets-et-dictionnaires" title="Permanent link">&para;</a></h3>
<h4 id="norms"><strong>norms()</strong><a class="headerlink" href="#norms" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th><strong>Valeurs</strong></th>
<th><strong>Module PyTorch</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>"Relu"</strong></td>
<td><code>nn.ReLU()</code></td>
<td>Fonction d'activation ReLU classique (Rectified Linear Unit).</td>
</tr>
<tr>
<td><strong>"LeakyRelu"</strong></td>
<td><code>nn.LeakyReLU()</code></td>
<td>ReLU avec un petit coefficient pour les valeurs négatives (paramètre <code>negative_slope</code>).</td>
</tr>
<tr>
<td><strong>"ELU"</strong></td>
<td><code>nn.ELU()</code></td>
<td>Fonction d'activation ELU (Exponential Linear Unit), qui a une meilleure gestion des valeurs négatives.</td>
</tr>
<tr>
<td><strong>"SELU"</strong></td>
<td><code>nn.SELU()</code></td>
<td>SELU (Scaled Exponential Linear Unit), une version améliorée de l'ELU pour des réseaux auto-normalisants.</td>
</tr>
<tr>
<td><strong>"GELU"</strong></td>
<td><code>nn.GELU()</code></td>
<td>GELU (Gaussian Error Linear Unit), une activation probabiliste basée sur une fonction gaussienne.</td>
</tr>
<tr>
<td><strong>"Sigmoid"</strong></td>
<td><code>nn.Sigmoid()</code></td>
<td>Fonction d'activation Sigmoid, qui produit une sortie entre 0 et 1.</td>
</tr>
<tr>
<td><strong>"Tanh"</strong></td>
<td><code>nn.Tanh()</code></td>
<td>Fonction d'activation Tanh, avec une sortie dans l'intervalle [-1, 1].</td>
</tr>
<tr>
<td><strong>"Hardtanh"</strong></td>
<td><code>nn.Hardtanh()</code></td>
<td>Variante de Tanh, avec des sorties limitées entre une plage spécifiée.</td>
</tr>
<tr>
<td><strong>"PReLU"</strong></td>
<td><code>nn.PReLU()</code></td>
<td>Parametric ReLU, une version de ReLU où le coefficient <code>slope</code> est appris.</td>
</tr>
<tr>
<td><strong>"RReLU"</strong></td>
<td><code>nn.RReLU()</code></td>
<td>Randomized ReLU, une version de PReLU avec un paramètre de pente aléatoire pendant l'entraînement.</td>
</tr>
<tr>
<td><strong>"Softplus"</strong></td>
<td><code>nn.Softplus()</code></td>
<td>Fonction d'activation qui approxime ReLU mais de manière lissée.</td>
</tr>
<tr>
<td><strong>"Softsign"</strong></td>
<td><code>nn.Softsign()</code></td>
<td>Fonction d'activation similaire à Tanh mais plus souple, avec des valeurs dans [-1, 1].</td>
</tr>
</tbody>
</table>
<hr />
<h4 id="crits"><strong>crits()</strong><a class="headerlink" href="#crits" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th><strong>Valeurs</strong></th>
<th><strong>Module PyTorch</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>"MSE"</strong></td>
<td><code>nn.MSELoss()</code></td>
<td>Mean Squared Error Loss, utilisée pour les régressions.</td>
</tr>
<tr>
<td><strong>"L1"</strong></td>
<td><code>nn.L1Loss()</code></td>
<td>L1 Loss (erreur absolue), souvent utilisée pour la régularisation.</td>
</tr>
<tr>
<td><strong>"SmoothL1"</strong></td>
<td><code>nn.SmoothL1Loss()</code></td>
<td>Smooth L1 Loss, une combinaison de L1 et de MSE, moins sensible aux outliers.</td>
</tr>
<tr>
<td><strong>"Huber"</strong></td>
<td><code>nn.HuberLoss()</code></td>
<td>Fonction de perte Huber, une version lissée de L1 et MSE, moins affectée par les grands écarts.</td>
</tr>
<tr>
<td><strong>"CrossEntropy"</strong></td>
<td><code>nn.CrossEntropyLoss()</code></td>
<td>Perte de Cross-Entropy, utilisée pour les problèmes de classification multi-classes.</td>
</tr>
<tr>
<td><strong>"BCE"</strong></td>
<td><code>nn.BCELoss()</code></td>
<td>Binary Cross-Entropy Loss, utilisée pour les tâches de classification binaire.</td>
</tr>
<tr>
<td><strong>"BCEWithLogits"</strong></td>
<td><code>nn.BCEWithLogitsLoss()</code></td>
<td>BCE Loss combinée avec un calcul de logits, plus stable numériquement que l'utilisation séparée de <code>Sigmoid</code> et <code>BCELoss</code>.</td>
</tr>
<tr>
<td><strong>"KLDiv"</strong></td>
<td><code>nn.KLDivLoss()</code></td>
<td>Perte de divergence de Kullback-Leibler, souvent utilisée pour des modèles probabilistes.</td>
</tr>
<tr>
<td><strong>"PoissonNLL"</strong></td>
<td><code>nn.PoissonNLLLoss()</code></td>
<td>Perte de log-vraisemblance pour une distribution de Poisson, utilisée pour la modélisation de comptages.</td>
</tr>
<tr>
<td><strong>"MultiLabelSoftMargin"</strong></td>
<td><code>nn.MultiLabelSoftMarginLoss()</code></td>
<td>Perte utilisée pour les problèmes de classification multi-étiquettes.</td>
</tr>
</tbody>
</table>
<hr />
<h4 id="optims"><strong>optims()</strong><a class="headerlink" href="#optims" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th><strong>Valeurs</strong></th>
<th><strong>Module PyTorch</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>"Adadelta"</strong></td>
<td><code>optim.Adadelta()</code></td>
<td>Optimiseur Adadelta, basé sur les gradients adaptatifs, sans nécessité de réglage du taux d'apprentissage.</td>
</tr>
<tr>
<td><strong>"Adafactor"</strong></td>
<td><code>optim.Adafactor()</code></td>
<td>Optimiseur Adafactor, variant d'Adam avec une mise à jour plus efficace de la mémoire pour de grands modèles.</td>
</tr>
<tr>
<td><strong>"Adam"</strong></td>
<td><code>optim.Adam()</code></td>
<td>Optimiseur Adam, utilisant un gradient stochastique adaptatif avec des moyennes mobiles des gradients et des carrés des gradients.</td>
</tr>
<tr>
<td><strong>"AdamW"</strong></td>
<td><code>optim.AdamW()</code></td>
<td>Optimiseur Adam avec une régularisation L2 (weight decay) distincte, plus efficace que <code>Adam</code> avec <code>weight_decay</code>.</td>
</tr>
<tr>
<td><strong>"Adamax"</strong></td>
<td><code>optim.Adamax()</code></td>
<td>Version d'Adam utilisant une norme infinie pour les gradients, plus stable pour certaines configurations.</td>
</tr>
<tr>
<td><strong>"ASGD"</strong></td>
<td><code>optim.ASGD()</code></td>
<td>Optimiseur ASGD (Averaged Stochastic Gradient Descent), utilisé pour de grandes données avec une moyenne des gradients.</td>
</tr>
<tr>
<td><strong>"NAdam"</strong></td>
<td><code>optim.NAdam()</code></td>
<td>Optimiseur NAdam, une version améliorée d'Adam avec une adaptation des moments de second ordre.</td>
</tr>
<tr>
<td><strong>"RAdam"</strong></td>
<td><code>optim.RAdam()</code></td>
<td>Optimiseur RAdam, une version robuste de l'Adam qui ajuste dynamiquement les moments pour stabiliser l'entraînement.</td>
</tr>
<tr>
<td><strong>"RMSprop"</strong></td>
<td><code>optim.RMSprop()</code></td>
<td>Optimiseur RMSprop, utilisant une moyenne mobile des carrés des gradients pour réduire les oscillations.</td>
</tr>
<tr>
<td><strong>"Rprop"</strong></td>
<td><code>optim.Rprop()</code></td>
<td>Optimiseur Rprop, basé sur les mises à jour des poids indépendantes des gradients.</td>
</tr>
<tr>
<td><strong>"SGD"</strong></td>
<td><code>optim.SGD()</code></td>
<td>Descente de gradient stochastique classique, souvent utilisée avec un taux d'apprentissage constant ou ajusté.</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="device-et-configuration">Device et configuration<a class="headerlink" href="#device-et-configuration" title="Permanent link">&para;</a></h3>
<h4 id="apple-silicon-macos"><strong>Apple Silicon (macOS)</strong><a class="headerlink" href="#apple-silicon-macos" title="Permanent link">&para;</a></h4>
<ul>
<li>Si le système d'exploitation est macOS (nommé <code>darwin</code> dans <code>platform.system()</code>), la fonction vérifie si l'accélérateur <strong>Metal Performance Shaders</strong> (MPS) est disponible sur l'appareil.</li>
<li>Si MPS est disponible (<code>torch.backends.mps.is_available()</code>), l'appareil cible sera défini sur <strong>MPS</strong> (c'est un équivalent de CUDA pour les appareils Apple Silicon).</li>
</ul>
<h4 id="windows"><strong>Windows</strong><a class="headerlink" href="#windows" title="Permanent link">&para;</a></h4>
<ul>
<li>Si le système d'exploitation est Windows, la fonction vérifie d'abord si <strong>CUDA</strong> (NVIDIA) est disponible avec <code>torch.cuda.is_available()</code>. Si c'est le cas, le périphérique sera défini sur <strong>CUDA</strong>.</li>
</ul>
<h4 id="linux"><strong>Linux</strong><a class="headerlink" href="#linux" title="Permanent link">&para;</a></h4>
<ul>
<li>Si le système d'exploitation est Linux, plusieurs vérifications sont effectuées :</li>
<li><strong>CUDA</strong> (NVIDIA) : Si <code>torch.cuda.is_available()</code> renvoie <code>True</code>, le périphérique sera défini sur <strong>CUDA</strong>.</li>
<li><strong>ROCm</strong> (AMD) : Si le système supporte <strong>ROCm</strong> via <code>torch.backends.hip.is_available()</code>, l'appareil sera défini sur <strong>CUDA</strong> (ROCm est utilisé pour les cartes AMD dans le cadre de l'API CUDA).</li>
<li><strong>Intel oneAPI / XPU</strong> : Si le système prend en charge <strong>Intel oneAPI</strong> ou <strong>XPU</strong> via <code>torch.xpu.is_available()</code>, le périphérique sera défini sur <strong>XPU</strong>.</li>
</ul>
<h4 id="systeme-non-reconnu"><strong>Système non reconnu</strong><a class="headerlink" href="#systeme-non-reconnu" title="Permanent link">&para;</a></h4>
<ul>
<li>Si aucune des conditions ci-dessus n'est remplie, la fonction retourne <strong>CPU</strong> comme périphérique par défaut.</li>
</ul>
<hr />
<h3 id="parametres-matplotlib-et-pytorch">Paramètres matplotlib et PyTorch<a class="headerlink" href="#parametres-matplotlib-et-pytorch" title="Permanent link">&para;</a></h3>
<ul>
<li>Style global pour fond transparent et texte gris  </li>
<li>Optimisations CUDA activées pour TF32, matmul et convolutions  </li>
<li>Autograd configuré pour privilégier les performances</li>
</ul>
<hr />
<h3 id="notes-generales">Notes générales<a class="headerlink" href="#notes-generales" title="Permanent link">&para;</a></h3>
<ul>
<li>Toutes les méthodes de MLP utilisent les tenseurs sur le device global (CPU ou GPU)  </li>
<li>Les images doivent être normalisées entre 0 et 1  </li>
<li>Les fonctions interactives (<code>plot</code>, <code>compare</code>) utilisent matplotlib en mode interactif  </li>
<li>Le module est conçu pour fonctionner dans Jupyter et scripts Python classiques</li>
</ul>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="MLP/" class="btn btn-neutral float-right" title="MLP">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/xXxFetraxXx/NeuralNetworks" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
    
      <span><a href="MLP/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="js/jquery-3.6.0.min.js"></script>
    <script>var base_url = ".";</script>
    <script src="js/theme_extra.js"></script>
    <script src="js/theme.js"></script>
      <script src="search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>

<!--
MkDocs version : 1.6.1
Build Date UTC : 2025-11-25 17:46:12.861133+00:00
-->
