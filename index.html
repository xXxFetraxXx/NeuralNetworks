<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="description" content="Multi-Layer Perceptrons with multi-Fourier encoding, variable learning rate, visualization and PyTorch compilation" /><meta name="author" content="Alexandre Brun" /><link rel="canonical" href="https://xXxFetraxXx.github.io/NeuralNetworks/" />
      <link rel="shortcut icon" href="img/favicon.ico" />
    <title>NeuralNetworks</title>
    <link rel="stylesheet" href="css/theme.css" />
    <link rel="stylesheet" href="css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Accueil";
        var mkdocs_page_input_path = "index.md";
        var mkdocs_page_url = "/NeuralNetworks/";
      </script>
    
    <!--[if lt IE 9]>
      <script src="js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="." class="icon icon-home"> NeuralNetworks
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">Accueil</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#contenu-principal">Contenu principal</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#classes">Classes</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#mlp">MLP</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#trainer">Trainer</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#dictionnaires">Dictionnaires</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#norms">norms()</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#crits">crits()</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#optims">optims()</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#device">device</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#apple-silicon-macos">Apple Silicon (macOS)</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#windows">Windows</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#linux">Linux</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#systeme-non-reconnu">Système non reconnu</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#parametres-matplotlib-et-pytorch">Paramètres matplotlib et PyTorch</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Tools</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" >image</a>
    <ul>
                <li class="toctree-l2"><a class="" href="tools/image/image_from_url.md">image_from_url</a>
                </li>
                <li class="toctree-l2"><a class="" href="tools/image/plot.md">plot</a>
                </li>
                <li class="toctree-l2"><a class="" href="tools/image/compare.md">compare</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >MNIST</a>
    <ul>
                <li class="toctree-l2"><a class="" href="placeholder.md">data</a>
                </li>
                <li class="toctree-l2"><a class="" href="placeholder.md">evaluate</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >AirfRANS</a>
    <ul>
                <li class="toctree-l2"><a class="" href="placeholder.md">download</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="" href="placeholder.md">VKI-LS59</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Dependances</span></p>
              <ul>
                  <li class="toctree-l1"><a class="" href="https://pypi.org/project/torch/">torch</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="https://pypi.org/project/visualtorch/">visualtorch</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="https://pypi.org/project/random-fourier-features-pytorch/">rff</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="https://pypi.org/project/numpy/">numpy</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="https://pypi.org/project/matplotlib/">matplotlib</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="https://airfrans.readthedocs.io/en/latest/">airfrans</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Liens</span></p>
              <ul>
                  <li class="toctree-l1"><a class="" href="https://pypi.org/project/NeuralNetworks/">PyPI</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="https://github.com/xXxFetraxXx/NeuralNetworks">Source</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href=".">NeuralNetworks</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Accueil</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/xXxFetraxXx/NeuralNetworks/edit/master/docs/index.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="neuralnetworks-module">NeuralNetworks Module<a class="headerlink" href="#neuralnetworks-module" title="Permanent link">&para;</a></h1>
<p>Module complet pour la création, l'entraînement et la visualisation de Multi-Layer Perceptrons (MLP)<br />
avec encodage optionnel Fourier, gestion automatique des pertes, compilation Torch et outils<br />
de traitement d'images pour l'apprentissage sur des images RGB.</p>
<hr />
<h2 id="contenu-principal">Contenu principal<a class="headerlink" href="#contenu-principal" title="Permanent link">&para;</a></h2>
<h3 id="classes">Classes<a class="headerlink" href="#classes" title="Permanent link">&para;</a></h3>
<h4 id="mlp"><code>MLP</code><a class="headerlink" href="#mlp" title="Permanent link">&para;</a></h4>
<p>Multi-Layer Perceptron (MLP) avec encodage optionnel Fourier (RFF),<br />
suivi automatique des pertes, visualisation et compilation PyTorch.</p>
<p>Cette classe fournit :</p>
<ul>
<li>Un MLP entièrement configurable (dimensions, normalisation, activation)  </li>
<li>Option d'encodage Fourier (Random Fourier Features) sur les entrées  </li>
<li>Méthodes pour entraîner le réseau avec mini-batchs et AMP (Automatic Mixed Precision)  </li>
<li>Visualisation de l'architecture via visualtorch  </li>
<li>Suivi et affichage de la perte d'entraînement  </li>
<li>Accès aux poids, biais et nombre de paramètres  </li>
</ul>
<hr />
<h5 id="parameters">Parameters<a class="headerlink" href="#parameters" title="Permanent link">&para;</a></h5>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Type</th>
<th>Optional</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>input_size</code></td>
<td>int</td>
<td>Yes</td>
<td>Taille des données en entrée au réseau. Default: <code>1</code></td>
</tr>
<tr>
<td><code>output_size</code></td>
<td>int</td>
<td>Yes</td>
<td>Taille des données en sortie au réseau. Default: <code>1</code></td>
</tr>
<tr>
<td><code>hidden_layers</code></td>
<td>list[int]</td>
<td>Yes</td>
<td>Dimensions successives des couches intermédiaires du réseau. Default: <code>[1]</code></td>
</tr>
<tr>
<td><code>sigmas</code></td>
<td>list[float]</td>
<td>Yes</td>
<td>Liste de sigma pour encodages RFF. Si None : passthrough. Default: <code>None</code></td>
</tr>
<tr>
<td><code>fourier_input_size</code></td>
<td>int</td>
<td>Yes</td>
<td>WIP. Default: <code>2</code></td>
</tr>
<tr>
<td><code>nb_fourier</code></td>
<td>int</td>
<td>Yes</td>
<td>Nombre de fréquences utilisées pour les Fourier Features. Default: <code>8</code></td>
</tr>
<tr>
<td><code>norm</code></td>
<td>str</td>
<td>Yes</td>
<td>Type de normalisation / activation pour les couches cachées (ex: <code>"Relu"</code>). Default: <code>"Relu"</code></td>
</tr>
<tr>
<td><code>name</code></td>
<td>str</td>
<td>Yes</td>
<td>Nom du réseau pour identification ou affichage. Default: <code>"Net"</code></td>
</tr>
</tbody>
</table>
<hr />
<h5 id="attributes">Attributes<a class="headerlink" href="#attributes" title="Permanent link">&para;</a></h5>
<ul>
<li><code>losses : list[float]</code> — Historique des pertes cumulées lors de l'entraînement  </li>
<li><code>learnings : list[float]</code> — Historique des taux d'apprentissage utilisées lors de l'entraînement  </li>
<li><code>model : nn.Sequential</code> — MLP complet construit dynamiquement </li>
<li><code>name : str</code> — Nom du réseau</li>
</ul>
<hr />
<h4 id="trainer"><code>Trainer</code><a class="headerlink" href="#trainer" title="Permanent link">&para;</a></h4>
<hr />
<h5 id="parameters_1">Parameters<a class="headerlink" href="#parameters_1" title="Permanent link">&para;</a></h5>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Type</th>
<th>Optional</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>*nets</code></td>
<td>*MLP</td>
<td>No</td>
<td>Réseaux pour lesquels le trainer va entrainer.</td>
</tr>
<tr>
<td><code>inputs</code></td>
<td>np.array(float)</td>
<td>No</td>
<td>Données en entrée au réseau.</td>
</tr>
<tr>
<td><code>outputs</code></td>
<td>np.array(float)</td>
<td>No</td>
<td>Données en sortie au réseau.</td>
</tr>
<tr>
<td><code>test_size</code></td>
<td>float</td>
<td>Yes</td>
<td>Proportion des données à utiliser pendant l'entrainement. Si None : utilise toutes les données. Default: <code>None</code></td>
</tr>
<tr>
<td><code>optim</code></td>
<td>str</td>
<td>Yes</td>
<td>Nom de l’optimiseur à utiliser (doit exister dans <code>optims()</code>). Default: <code>"Adam"</code></td>
</tr>
<tr>
<td><code>init_lr</code></td>
<td>float</td>
<td>Yes</td>
<td>Taux d’apprentissage initial pour l’optimiseur. Default: <code>1e-3</code></td>
</tr>
<tr>
<td><code>crit</code></td>
<td>str</td>
<td>Yes</td>
<td>Fonction de perte à utiliser (doit exister dans <code>crits()</code>). Default: <code>"MSE"</code></td>
</tr>
<tr>
<td><code>batch_size</code></td>
<td>float</td>
<td>Yes</td>
<td>Taille des minibatchs. Default: <code>1024</code></td>
</tr>
</tbody>
</table>
<hr />
<h5 id="trainertrain"><code>Trainer.train</code><a class="headerlink" href="#trainertrain" title="Permanent link">&para;</a></h5>
<p>Lancement d'un entrainement avec le trainer définit</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Type</th>
<th>Optional</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>num_epochs</code></td>
<td>int</td>
<td>Yes</td>
<td>Nombres d'itérations à effectuer.</td>
</tr>
<tr>
<td><code>activate_tqdm</code></td>
<td>boolean</td>
<td>Yes</td>
<td>Utilisation d'une barre de progression.</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="dictionnaires">Dictionnaires<a class="headerlink" href="#dictionnaires" title="Permanent link">&para;</a></h3>
<h4 id="norms"><code>norms()</code><a class="headerlink" href="#norms" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th><strong>Valeurs</strong></th>
<th><strong>Module PyTorch</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>"ReLU"</strong></td>
<td><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html"><code>nn.ReLU()</code></a></td>
<td>Fonction d'activation ReLU classique (Rectified Linear Unit).</td>
</tr>
<tr>
<td><strong>"LeakyReLU"</strong></td>
<td><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html"><code>nn.LeakyReLU()</code></a></td>
<td>ReLU avec un petit coefficient pour les valeurs négatives (paramètre <code>negative_slope</code>).</td>
</tr>
<tr>
<td><strong>"ELU"</strong></td>
<td><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ELU.html"><code>nn.ELU()</code></a></td>
<td>Fonction d'activation ELU (Exponential Linear Unit), qui a une meilleure gestion des valeurs négatives.</td>
</tr>
<tr>
<td><strong>"SELU"</strong></td>
<td><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.SELU.html"><code>nn.SELU()</code></a></td>
<td>SELU (Scaled Exponential Linear Unit), une version améliorée de l'ELU pour des réseaux auto-normalisants.</td>
</tr>
<tr>
<td><strong>"GELU"</strong></td>
<td><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.GELU.html"><code>nn.GELU()</code></a></td>
<td>GELU (Gaussian Error Linear Unit), une activation probabiliste basée sur une fonction gaussienne.</td>
</tr>
<tr>
<td><strong>"Mish"</strong></td>
<td><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Mish.html"><code>nn.Mish()</code></a></td>
<td>ReLU différentiable en tout points avec passage négatif.</td>
</tr>
<tr>
<td><strong>"Softplus"</strong></td>
<td><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Softplus.html"><code>nn.Softplus()</code></a></td>
<td>Fonction d'activation qui approxime ReLU mais de manière lissée.</td>
</tr>
<tr>
<td><strong>"Sigmoid"</strong></td>
<td><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html"><code>nn.Sigmoid()</code></a></td>
<td>Fonction d'activation Sigmoid, qui produit une sortie entre 0 et 1.</td>
</tr>
<tr>
<td><strong>"Tanh"</strong></td>
<td><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Tanh.html"><code>nn.Tanh()</code></a></td>
<td>Fonction d'activation Tanh, avec une sortie dans l'intervalle [-1, 1].</td>
</tr>
<tr>
<td><strong>"Hardtanh"</strong></td>
<td><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Hardtanh.html"><code>nn.Hardtanh()</code></a></td>
<td>Variante de Tanh, avec des sorties limitées entre une plage spécifiée.</td>
</tr>
<tr>
<td><strong>"Softsign"</strong></td>
<td><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Softsign.html"><code>nn.Softsign()</code></a></td>
<td>Fonction d'activation similaire à Tanh mais plus souple, avec des valeurs dans [-1, 1].</td>
</tr>
</tbody>
</table>
<hr />
<h4 id="crits"><code>crits()</code><a class="headerlink" href="#crits" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th><strong>Valeurs</strong></th>
<th><strong>Module PyTorch</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>"MSE"</strong></td>
<td><a href="https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html"><code>nn.MSELoss</code></a></td>
<td>Mean Squared Error Loss, utilisée pour les régressions.</td>
</tr>
<tr>
<td><strong>"L1"</strong></td>
<td><code>nn.L1Loss()</code></td>
<td>L1 Loss (erreur absolue), souvent utilisée pour la régularisation.</td>
</tr>
<tr>
<td><strong>"SmoothL1"</strong></td>
<td><code>nn.SmoothL1Loss()</code></td>
<td>Smooth L1 Loss, une combinaison de L1 et de MSE, moins sensible aux outliers.</td>
</tr>
<tr>
<td><strong>"Huber"</strong></td>
<td><code>nn.HuberLoss()</code></td>
<td>Fonction de perte Huber, une version lissée de L1 et MSE, moins affectée par les grands écarts.</td>
</tr>
<tr>
<td><strong>"CrossEntropy"</strong></td>
<td><code>nn.CrossEntropyLoss()</code></td>
<td>Perte de Cross-Entropy, utilisée pour les problèmes de classification multi-classes.</td>
</tr>
<tr>
<td><strong>"KLDiv"</strong></td>
<td><code>nn.KLDivLoss()</code></td>
<td>Perte de divergence de Kullback-Leibler, souvent utilisée pour des modèles probabilistes.</td>
</tr>
<tr>
<td><strong>"PoissonNLL"</strong></td>
<td><code>nn.PoissonNLLLoss()</code></td>
<td>Perte de log-vraisemblance pour une distribution de Poisson, utilisée pour la modélisation de comptages.</td>
</tr>
<tr>
<td><strong>"MultiLabelSoftMargin"</strong></td>
<td><code>nn.MultiLabelSoftMarginLoss()</code></td>
<td>Perte utilisée pour les problèmes de classification multi-étiquettes.</td>
</tr>
</tbody>
</table>
<hr />
<h4 id="optims"><code>optims()</code><a class="headerlink" href="#optims" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th><strong>Valeurs</strong></th>
<th><strong>Module PyTorch</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>"Adadelta"</strong></td>
<td><code>optim.Adadelta()</code></td>
<td>Optimiseur Adadelta, basé sur les gradients adaptatifs, sans nécessité de réglage du taux d'apprentissage.</td>
</tr>
<tr>
<td><strong>"Adafactor"</strong></td>
<td><code>optim.Adafactor()</code></td>
<td>Optimiseur Adafactor, variant d'Adam avec une mise à jour plus efficace de la mémoire pour de grands modèles.</td>
</tr>
<tr>
<td><strong>"Adam"</strong></td>
<td><code>optim.Adam()</code></td>
<td>Optimiseur Adam, utilisant un gradient stochastique adaptatif avec des moyennes mobiles des gradients et des carrés des gradients.</td>
</tr>
<tr>
<td><strong>"AdamW"</strong></td>
<td><code>optim.AdamW()</code></td>
<td>Optimiseur Adam avec une régularisation L2 (weight decay) distincte, plus efficace que <code>Adam</code> avec <code>weight_decay</code>.</td>
</tr>
<tr>
<td><strong>"Adamax"</strong></td>
<td><code>optim.Adamax()</code></td>
<td>Version d'Adam utilisant une norme infinie pour les gradients, plus stable pour certaines configurations.</td>
</tr>
<tr>
<td><strong>"ASGD"</strong></td>
<td><code>optim.ASGD()</code></td>
<td>Optimiseur ASGD (Averaged Stochastic Gradient Descent), utilisé pour de grandes données avec une moyenne des gradients.</td>
</tr>
<tr>
<td><strong>"NAdam"</strong></td>
<td><code>optim.NAdam()</code></td>
<td>Optimiseur NAdam, une version améliorée d'Adam avec une adaptation des moments de second ordre.</td>
</tr>
<tr>
<td><strong>"RAdam"</strong></td>
<td><code>optim.RAdam()</code></td>
<td>Optimiseur RAdam, une version robuste de l'Adam qui ajuste dynamiquement les moments pour stabiliser l'entraînement.</td>
</tr>
<tr>
<td><strong>"RMSprop"</strong></td>
<td><code>optim.RMSprop()</code></td>
<td>Optimiseur RMSprop, utilisant une moyenne mobile des carrés des gradients pour réduire les oscillations.</td>
</tr>
<tr>
<td><strong>"Rprop"</strong></td>
<td><code>optim.Rprop()</code></td>
<td>Optimiseur Rprop, basé sur les mises à jour des poids indépendantes des gradients.</td>
</tr>
<tr>
<td><strong>"SGD"</strong></td>
<td><code>optim.SGD()</code></td>
<td>Descente de gradient stochastique classique, souvent utilisée avec un taux d'apprentissage constant ou ajusté.</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="device"><code>device</code><a class="headerlink" href="#device" title="Permanent link">&para;</a></h3>
<p>variable principale d'allocation des performances</p>
<h4 id="apple-silicon-macos"><strong>Apple Silicon (macOS)</strong><a class="headerlink" href="#apple-silicon-macos" title="Permanent link">&para;</a></h4>
<ul>
<li>Si le système d'exploitation est macOS (nommé <code>darwin</code> dans <code>platform.system()</code>), la fonction vérifie si l'accélérateur <strong>Metal Performance Shaders</strong> (MPS) est disponible sur l'appareil.</li>
<li>Si MPS est disponible (<code>torch.backends.mps.is_available()</code>), l'appareil cible sera défini sur <strong>MPS</strong> (c'est un équivalent de CUDA pour les appareils Apple Silicon).</li>
</ul>
<h4 id="windows"><strong>Windows</strong><a class="headerlink" href="#windows" title="Permanent link">&para;</a></h4>
<ul>
<li>Si le système d'exploitation est Windows, la fonction vérifie d'abord si <strong>CUDA</strong> (NVIDIA) est disponible avec <code>torch.cuda.is_available()</code>. Si c'est le cas, le périphérique sera défini sur <strong>CUDA</strong>.</li>
</ul>
<h4 id="linux"><strong>Linux</strong><a class="headerlink" href="#linux" title="Permanent link">&para;</a></h4>
<ul>
<li>Si le système d'exploitation est Linux, plusieurs vérifications sont effectuées :</li>
<li><strong>CUDA</strong> (NVIDIA) : Si <code>torch.cuda.is_available()</code> renvoie <code>True</code>, le périphérique sera défini sur <strong>CUDA</strong>.</li>
<li><strong>ROCm</strong> (AMD) : Si le système supporte <strong>ROCm</strong> via <code>torch.backends.hip.is_available()</code>, l'appareil sera défini sur <strong>CUDA</strong> (ROCm est utilisé pour les cartes AMD dans le cadre de l'API CUDA).</li>
<li><strong>Intel oneAPI / XPU</strong> : Si le système prend en charge <strong>Intel oneAPI</strong> ou <strong>XPU</strong> via <code>torch.xpu.is_available()</code>, le périphérique sera défini sur <strong>XPU</strong>.</li>
</ul>
<h4 id="systeme-non-reconnu"><strong>Système non reconnu</strong><a class="headerlink" href="#systeme-non-reconnu" title="Permanent link">&para;</a></h4>
<ul>
<li>Si aucune des conditions ci-dessus n'est remplie, la fonction retourne <strong>CPU</strong> comme périphérique par défaut.</li>
</ul>
<hr />
<h3 id="parametres-matplotlib-et-pytorch">Paramètres matplotlib et PyTorch<a class="headerlink" href="#parametres-matplotlib-et-pytorch" title="Permanent link">&para;</a></h3>
<ul>
<li>Style global pour fond transparent et texte gris  </li>
<li>Optimisations CUDA activées pour TF32, matmul et convolutions  </li>
<li>Autograd configuré pour privilégier les performances</li>
</ul>
<hr />
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/xXxFetraxXx/NeuralNetworks" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
    
  </span>
</div>
    <script src="js/jquery-3.6.0.min.js"></script>
    <script>var base_url = ".";</script>
    <script src="js/theme_extra.js"></script>
    <script src="js/theme.js"></script>
      <script src="search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>

<!--
MkDocs version : 1.6.1
Build Date UTC : 2026-01-16 18:26:01.933488+00:00
-->
